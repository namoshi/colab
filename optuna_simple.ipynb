{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNnBIfEhAkA3DAl1E7IvryQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namoshi/colab/blob/master/optuna_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh9YlgrWJmdu",
        "outputId": "bb3a3c82-12aa-4d48-f484-16c36457044e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Optuna example that optimizes multi-layer perceptrons using PyTorch.\n",
        "\n",
        "In this example, we optimize the validation accuracy of fashion product recognition using\n",
        "PyTorch and FashionMNIST. We optimize the neural network architecture as well as the optimizer\n",
        "configuration. As it is too time consuming to use the whole FashionMNIST dataset,\n",
        "we here use a small subset of it.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 20\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 10\n"
      ],
      "metadata": {
        "id": "d1JVQZoDKNhj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    layers = []\n",
        "\n",
        "    in_features = 28 * 28\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
        "        layers.append(nn.Dropout(p))\n",
        "\n",
        "        in_features = out_features\n",
        "    layers.append(nn.Linear(in_features, CLASSES))\n",
        "\n",
        "#    layers.append(nn.LogSoftmax(dim=1))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def get_mnist():\n",
        "    # Load FashionMNIST dataset.\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [ \"AdamW\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    wd = trial.suggest_float(\"wd\", 1e-5, 1e-1)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "    # Get the FashionMNIST dataset.\n",
        "    train_loader, valid_loader = get_mnist()\n",
        "\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "#            loss = F.nll_loss(output, target)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "lKyH48QpKen-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=200, timeout=600)\n",
        "\n",
        "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: \", trial.value)\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpXJtp6KJzyz",
        "outputId": "aa53c7ce-382e-4cb2-a647-55d864ae1a5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-12 04:23:49,106] A new study created in memory with name: no-name-bceaaa1e-cae8-4df3-a8fe-ccc1c711aa50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16209392.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 274121.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5063437.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 22010476.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /content/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-12 04:24:11,806] Trial 0 finished with value: 0.78671875 and parameters: {'n_layers': 2, 'n_units_l0': 118, 'dropout_l0': 0.2840172170284108, 'n_units_l1': 25, 'dropout_l1': 0.4682544127830698, 'optimizer': 'AdamW', 'lr': 0.013552448762641322, 'wd': 0.08137873477466773}. Best is trial 0 with value: 0.78671875.\n",
            "[I 2024-04-12 04:24:24,483] Trial 1 finished with value: 0.63984375 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.3668694798677581, 'optimizer': 'SGD', 'lr': 0.0028550548013370667, 'wd': 0.07206787067357004}. Best is trial 0 with value: 0.78671875.\n",
            "[I 2024-04-12 04:24:37,398] Trial 2 finished with value: 0.09296875 and parameters: {'n_layers': 3, 'n_units_l0': 42, 'dropout_l0': 0.27003850923153155, 'n_units_l1': 90, 'dropout_l1': 0.4538682550747703, 'n_units_l2': 25, 'dropout_l2': 0.39128174581011554, 'optimizer': 'SGD', 'lr': 0.000757381080223763, 'wd': 0.07369827451257853}. Best is trial 0 with value: 0.78671875.\n",
            "[I 2024-04-12 04:24:50,229] Trial 3 finished with value: 0.13046875 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'dropout_l0': 0.3801530651313536, 'n_units_l1': 89, 'dropout_l1': 0.22181575319148567, 'n_units_l2': 77, 'dropout_l2': 0.4886388029755407, 'optimizer': 'AdamW', 'lr': 1.2868743105861495e-05, 'wd': 0.07082176980357625}. Best is trial 0 with value: 0.78671875.\n",
            "[I 2024-04-12 04:25:02,938] Trial 4 finished with value: 0.584375 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'dropout_l0': 0.2485856839612509, 'n_units_l1': 6, 'dropout_l1': 0.289938525030868, 'optimizer': 'AdamW', 'lr': 0.00037914041919795687, 'wd': 0.0038818294757611877}. Best is trial 0 with value: 0.78671875.\n",
            "[I 2024-04-12 04:25:15,758] Trial 5 finished with value: 0.82890625 and parameters: {'n_layers': 1, 'n_units_l0': 118, 'dropout_l0': 0.4127125063430729, 'optimizer': 'AdamW', 'lr': 0.001772288471020972, 'wd': 0.04149791296895}. Best is trial 5 with value: 0.82890625.\n",
            "[I 2024-04-12 04:25:28,409] Trial 6 finished with value: 0.67265625 and parameters: {'n_layers': 2, 'n_units_l0': 101, 'dropout_l0': 0.3544889480557335, 'n_units_l1': 74, 'dropout_l1': 0.2896967167524872, 'optimizer': 'AdamW', 'lr': 8.090765486818914e-05, 'wd': 0.025231131667536932}. Best is trial 5 with value: 0.82890625.\n",
            "[I 2024-04-12 04:25:29,047] Trial 7 pruned. \n",
            "[I 2024-04-12 04:25:41,803] Trial 8 finished with value: 0.66953125 and parameters: {'n_layers': 3, 'n_units_l0': 11, 'dropout_l0': 0.2906082212208224, 'n_units_l1': 70, 'dropout_l1': 0.4623577874036597, 'n_units_l2': 61, 'dropout_l2': 0.4971557297614545, 'optimizer': 'AdamW', 'lr': 0.0005132638679578996, 'wd': 0.0971665789186494}. Best is trial 5 with value: 0.82890625.\n",
            "[I 2024-04-12 04:25:42,586] Trial 9 pruned. \n",
            "[I 2024-04-12 04:25:55,075] Trial 10 finished with value: 0.72890625 and parameters: {'n_layers': 1, 'n_units_l0': 78, 'dropout_l0': 0.47328889062248636, 'optimizer': 'SGD', 'lr': 0.034317950136581676, 'wd': 0.04352171294499477}. Best is trial 5 with value: 0.82890625.\n",
            "[I 2024-04-12 04:26:07,310] Trial 11 finished with value: 0.78515625 and parameters: {'n_layers': 1, 'n_units_l0': 127, 'dropout_l0': 0.20366642739730367, 'optimizer': 'AdamW', 'lr': 0.035443015083358495, 'wd': 0.046659371016642186}. Best is trial 5 with value: 0.82890625.\n",
            "[I 2024-04-12 04:26:20,011] Trial 12 finished with value: 0.778125 and parameters: {'n_layers': 1, 'n_units_l0': 80, 'dropout_l0': 0.44920615565156713, 'optimizer': 'AdamW', 'lr': 0.011645569990770219, 'wd': 0.032083481254182075}. Best is trial 5 with value: 0.82890625.\n",
            "[I 2024-04-12 04:26:20,952] Trial 13 pruned. \n",
            "[I 2024-04-12 04:26:33,105] Trial 14 finished with value: 0.8484375 and parameters: {'n_layers': 1, 'n_units_l0': 94, 'dropout_l0': 0.41886727030070653, 'optimizer': 'AdamW', 'lr': 0.0026314243646696433, 'wd': 0.08311888397385525}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:26:45,441] Trial 15 finished with value: 0.84375 and parameters: {'n_layers': 1, 'n_units_l0': 91, 'dropout_l0': 0.4210153773964465, 'optimizer': 'AdamW', 'lr': 0.0023990941022154952, 'wd': 0.05726334227953328}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:26:57,635] Trial 16 finished with value: 0.8109375 and parameters: {'n_layers': 1, 'n_units_l0': 87, 'dropout_l0': 0.49610029996361615, 'optimizer': 'AdamW', 'lr': 0.008838885821524313, 'wd': 0.06043010756500968}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:26:58,329] Trial 17 pruned. \n",
            "[I 2024-04-12 04:26:59,030] Trial 18 pruned. \n",
            "[I 2024-04-12 04:26:59,737] Trial 19 pruned. \n",
            "[I 2024-04-12 04:27:12,133] Trial 20 finished with value: 0.84453125 and parameters: {'n_layers': 1, 'n_units_l0': 73, 'dropout_l0': 0.32949492925287394, 'optimizer': 'AdamW', 'lr': 0.005286858547378747, 'wd': 0.054470158531162625}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:27:24,438] Trial 21 finished with value: 0.81328125 and parameters: {'n_layers': 1, 'n_units_l0': 70, 'dropout_l0': 0.321636581430291, 'optimizer': 'AdamW', 'lr': 0.004797744669617461, 'wd': 0.05625321752236189}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:27:36,752] Trial 22 finished with value: 0.8328125 and parameters: {'n_layers': 1, 'n_units_l0': 95, 'dropout_l0': 0.3336851346445359, 'optimizer': 'AdamW', 'lr': 0.0011461260213158672, 'wd': 0.03321142580192884}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:27:49,009] Trial 23 finished with value: 0.82734375 and parameters: {'n_layers': 1, 'n_units_l0': 67, 'dropout_l0': 0.43662824953456, 'optimizer': 'AdamW', 'lr': 0.004413087616958052, 'wd': 0.05255906587971614}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:27:50,285] Trial 24 pruned. \n",
            "[I 2024-04-12 04:28:02,554] Trial 25 finished with value: 0.828125 and parameters: {'n_layers': 1, 'n_units_l0': 82, 'dropout_l0': 0.3878587516259975, 'optimizer': 'AdamW', 'lr': 0.006886530254675873, 'wd': 0.06529658207816749}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:28:03,253] Trial 26 pruned. \n",
            "[I 2024-04-12 04:28:03,947] Trial 27 pruned. \n",
            "[I 2024-04-12 04:28:04,629] Trial 28 pruned. \n",
            "[I 2024-04-12 04:28:05,342] Trial 29 pruned. \n",
            "[I 2024-04-12 04:28:06,108] Trial 30 pruned. \n",
            "[I 2024-04-12 04:28:08,298] Trial 31 pruned. \n",
            "[I 2024-04-12 04:28:20,845] Trial 32 finished with value: 0.83046875 and parameters: {'n_layers': 1, 'n_units_l0': 94, 'dropout_l0': 0.3381070382749939, 'optimizer': 'AdamW', 'lr': 0.0028275668176269354, 'wd': 0.025848849937408654}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:28:33,405] Trial 33 finished with value: 0.8265625 and parameters: {'n_layers': 1, 'n_units_l0': 109, 'dropout_l0': 0.3236588549855923, 'optimizer': 'AdamW', 'lr': 0.006251789835412515, 'wd': 0.04349786717613333}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:28:34,097] Trial 34 pruned. \n",
            "[I 2024-04-12 04:28:36,598] Trial 35 pruned. \n",
            "[I 2024-04-12 04:28:37,285] Trial 36 pruned. \n",
            "[I 2024-04-12 04:28:37,980] Trial 37 pruned. \n",
            "[I 2024-04-12 04:28:38,673] Trial 38 pruned. \n",
            "[I 2024-04-12 04:28:39,392] Trial 39 pruned. \n",
            "[I 2024-04-12 04:28:40,155] Trial 40 pruned. \n",
            "[I 2024-04-12 04:28:52,511] Trial 41 finished with value: 0.8484375 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.33562149720930445, 'optimizer': 'AdamW', 'lr': 0.002276420490051236, 'wd': 0.023141485468740508}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:28:53,216] Trial 42 pruned. \n",
            "[I 2024-04-12 04:29:05,628] Trial 43 finished with value: 0.8328125 and parameters: {'n_layers': 1, 'n_units_l0': 110, 'dropout_l0': 0.33362743442109744, 'optimizer': 'AdamW', 'lr': 0.0020506402031651417, 'wd': 0.021070128599369777}. Best is trial 14 with value: 0.8484375.\n",
            "[I 2024-04-12 04:29:06,312] Trial 44 pruned. \n",
            "[I 2024-04-12 04:29:07,580] Trial 45 pruned. \n",
            "[I 2024-04-12 04:29:08,501] Trial 46 pruned. \n",
            "[I 2024-04-12 04:29:09,571] Trial 47 pruned. \n",
            "[I 2024-04-12 04:29:10,318] Trial 48 pruned. \n",
            "[I 2024-04-12 04:29:10,990] Trial 49 pruned. \n",
            "[I 2024-04-12 04:29:12,242] Trial 50 pruned. \n",
            "[I 2024-04-12 04:29:24,785] Trial 51 finished with value: 0.8546875 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.3323519583625443, 'optimizer': 'AdamW', 'lr': 0.0022068733865457163, 'wd': 0.024385364580468}. Best is trial 51 with value: 0.8546875.\n",
            "[I 2024-04-12 04:29:37,293] Trial 52 finished with value: 0.8421875 and parameters: {'n_layers': 1, 'n_units_l0': 104, 'dropout_l0': 0.3461454179748521, 'optimizer': 'AdamW', 'lr': 0.0029328296770551295, 'wd': 0.09844601959844684}. Best is trial 51 with value: 0.8546875.\n",
            "[I 2024-04-12 04:29:39,129] Trial 53 pruned. \n",
            "[I 2024-04-12 04:29:40,417] Trial 54 pruned. \n",
            "[I 2024-04-12 04:29:42,285] Trial 55 pruned. \n",
            "[I 2024-04-12 04:29:43,017] Trial 56 pruned. \n",
            "[I 2024-04-12 04:29:43,699] Trial 57 pruned. \n",
            "[I 2024-04-12 04:29:44,678] Trial 58 pruned. \n",
            "[I 2024-04-12 04:29:49,909] Trial 59 pruned. \n",
            "[I 2024-04-12 04:29:51,235] Trial 60 pruned. \n",
            "[I 2024-04-12 04:29:51,933] Trial 61 pruned. \n",
            "[I 2024-04-12 04:30:04,308] Trial 62 finished with value: 0.828125 and parameters: {'n_layers': 1, 'n_units_l0': 85, 'dropout_l0': 0.32845798567413614, 'optimizer': 'AdamW', 'lr': 0.003798577409036995, 'wd': 0.05731207762726381}. Best is trial 51 with value: 0.8546875.\n",
            "[I 2024-04-12 04:30:04,973] Trial 63 pruned. \n",
            "[I 2024-04-12 04:30:05,657] Trial 64 pruned. \n",
            "[I 2024-04-12 04:30:06,917] Trial 65 pruned. \n",
            "[I 2024-04-12 04:30:07,589] Trial 66 pruned. \n",
            "[I 2024-04-12 04:30:20,096] Trial 67 finished with value: 0.82578125 and parameters: {'n_layers': 1, 'n_units_l0': 116, 'dropout_l0': 0.43019673569907196, 'optimizer': 'AdamW', 'lr': 0.005560949159066864, 'wd': 0.03323955938788069}. Best is trial 51 with value: 0.8546875.\n",
            "[I 2024-04-12 04:30:21,039] Trial 68 pruned. \n",
            "[I 2024-04-12 04:30:22,105] Trial 69 pruned. \n",
            "[I 2024-04-12 04:30:22,790] Trial 70 pruned. \n",
            "[I 2024-04-12 04:30:24,020] Trial 71 pruned. \n",
            "[I 2024-04-12 04:30:26,394] Trial 72 pruned. \n",
            "[I 2024-04-12 04:30:27,625] Trial 73 pruned. \n",
            "[I 2024-04-12 04:30:28,885] Trial 74 pruned. \n",
            "[I 2024-04-12 04:30:41,134] Trial 75 finished with value: 0.82265625 and parameters: {'n_layers': 1, 'n_units_l0': 81, 'dropout_l0': 0.2898722868637688, 'optimizer': 'AdamW', 'lr': 0.004640600180824917, 'wd': 0.06145715342214419}. Best is trial 51 with value: 0.8546875.\n",
            "[I 2024-04-12 04:30:53,459] Trial 76 finished with value: 0.82421875 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.3523866781524996, 'optimizer': 'AdamW', 'lr': 0.006802721318128778, 'wd': 0.02812106922342376}. Best is trial 51 with value: 0.8546875.\n",
            "[I 2024-04-12 04:30:54,131] Trial 77 pruned. \n",
            "[I 2024-04-12 04:30:54,822] Trial 78 pruned. \n",
            "[I 2024-04-12 04:30:55,497] Trial 79 pruned. \n",
            "[I 2024-04-12 04:30:56,181] Trial 80 pruned. \n",
            "[I 2024-04-12 04:31:08,400] Trial 81 finished with value: 0.8609375 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.3379919057378356, 'optimizer': 'AdamW', 'lr': 0.002894309759249, 'wd': 0.026848497529578588}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:31:20,675] Trial 82 finished with value: 0.83984375 and parameters: {'n_layers': 1, 'n_units_l0': 90, 'dropout_l0': 0.3334711084076674, 'optimizer': 'AdamW', 'lr': 0.003870736398981357, 'wd': 0.05353543388953365}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:31:24,784] Trial 83 pruned. \n",
            "[I 2024-04-12 04:31:26,039] Trial 84 pruned. \n",
            "[I 2024-04-12 04:31:27,837] Trial 85 pruned. \n",
            "[I 2024-04-12 04:31:29,096] Trial 86 pruned. \n",
            "[I 2024-04-12 04:31:30,904] Trial 87 pruned. \n",
            "[I 2024-04-12 04:31:32,154] Trial 88 pruned. \n",
            "[I 2024-04-12 04:31:33,046] Trial 89 pruned. \n",
            "[I 2024-04-12 04:31:34,061] Trial 90 pruned. \n",
            "[I 2024-04-12 04:31:34,916] Trial 91 pruned. \n",
            "[I 2024-04-12 04:31:35,595] Trial 92 pruned. \n",
            "[I 2024-04-12 04:31:36,258] Trial 93 pruned. \n",
            "[I 2024-04-12 04:31:36,927] Trial 94 pruned. \n",
            "[I 2024-04-12 04:31:37,614] Trial 95 pruned. \n",
            "[I 2024-04-12 04:31:39,414] Trial 96 pruned. \n",
            "[I 2024-04-12 04:31:40,129] Trial 97 pruned. \n",
            "[I 2024-04-12 04:31:40,819] Trial 98 pruned. \n",
            "[I 2024-04-12 04:31:42,720] Trial 99 pruned. \n",
            "[I 2024-04-12 04:31:44,015] Trial 100 pruned. \n",
            "[I 2024-04-12 04:31:46,503] Trial 101 pruned. \n",
            "[I 2024-04-12 04:31:47,219] Trial 102 pruned. \n",
            "[I 2024-04-12 04:31:47,924] Trial 103 pruned. \n",
            "[I 2024-04-12 04:31:49,712] Trial 104 pruned. \n",
            "[I 2024-04-12 04:32:01,982] Trial 105 finished with value: 0.828125 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.2956860292955899, 'optimizer': 'AdamW', 'lr': 0.0021687054022411904, 'wd': 0.015081595788284972}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:32:03,232] Trial 106 pruned. \n",
            "[I 2024-04-12 04:32:15,823] Trial 107 finished with value: 0.82109375 and parameters: {'n_layers': 1, 'n_units_l0': 95, 'dropout_l0': 0.3345040257691339, 'optimizer': 'AdamW', 'lr': 0.004699501549263078, 'wd': 0.02888550996060921}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:32:28,005] Trial 108 finished with value: 0.8546875 and parameters: {'n_layers': 1, 'n_units_l0': 108, 'dropout_l0': 0.43309250950235545, 'optimizer': 'AdamW', 'lr': 0.0037125928853779127, 'wd': 0.04412632020342909}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:32:40,265] Trial 109 finished with value: 0.83046875 and parameters: {'n_layers': 1, 'n_units_l0': 109, 'dropout_l0': 0.432218139446688, 'optimizer': 'AdamW', 'lr': 0.007519965946246544, 'wd': 0.044541473245562055}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:32:40,970] Trial 110 pruned. \n",
            "[I 2024-04-12 04:32:41,656] Trial 111 pruned. \n",
            "[I 2024-04-12 04:32:43,538] Trial 112 pruned. \n",
            "[I 2024-04-12 04:32:55,727] Trial 113 finished with value: 0.84140625 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.35252328777756103, 'optimizer': 'AdamW', 'lr': 0.005914346064815244, 'wd': 0.047812951202067897}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:33:07,935] Trial 114 finished with value: 0.840625 and parameters: {'n_layers': 1, 'n_units_l0': 107, 'dropout_l0': 0.22264884401612173, 'optimizer': 'AdamW', 'lr': 0.006183461746575478, 'wd': 0.047504174865634234}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:33:10,128] Trial 115 pruned. \n",
            "[I 2024-04-12 04:33:22,660] Trial 116 finished with value: 0.82734375 and parameters: {'n_layers': 1, 'n_units_l0': 107, 'dropout_l0': 0.2545031502294607, 'optimizer': 'AdamW', 'lr': 0.0059784610576668375, 'wd': 0.04229889730925576}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:33:24,057] Trial 117 pruned. \n",
            "[I 2024-04-12 04:33:25,335] Trial 118 pruned. \n",
            "[I 2024-04-12 04:33:25,999] Trial 119 pruned. \n",
            "[I 2024-04-12 04:33:38,327] Trial 120 finished with value: 0.8296875 and parameters: {'n_layers': 1, 'n_units_l0': 113, 'dropout_l0': 0.27405290226332646, 'optimizer': 'AdamW', 'lr': 0.01598340821358063, 'wd': 0.058499888255417035}. Best is trial 81 with value: 0.8609375.\n",
            "[I 2024-04-12 04:33:39,006] Trial 121 pruned. \n",
            "[I 2024-04-12 04:33:39,675] Trial 122 pruned. \n",
            "[I 2024-04-12 04:33:40,397] Trial 123 pruned. \n",
            "[I 2024-04-12 04:33:41,082] Trial 124 pruned. \n",
            "[I 2024-04-12 04:33:41,754] Trial 125 pruned. \n",
            "[I 2024-04-12 04:33:42,446] Trial 126 pruned. \n",
            "[I 2024-04-12 04:33:54,701] Trial 127 finished with value: 0.8390625 and parameters: {'n_layers': 1, 'n_units_l0': 110, 'dropout_l0': 0.2508801039327804, 'optimizer': 'AdamW', 'lr': 0.0041198431443684345, 'wd': 0.05282559320398607}. Best is trial 81 with value: 0.8609375.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  128\n",
            "  Number of pruned trials:  88\n",
            "  Number of complete trials:  40\n",
            "Best trial:\n",
            "  Value:  0.8609375\n",
            "  Params: \n",
            "    n_layers: 1\n",
            "    n_units_l0: 92\n",
            "    dropout_l0: 0.3379919057378356\n",
            "    optimizer: AdamW\n",
            "    lr: 0.002894309759249\n",
            "    wd: 0.026848497529578588\n"
          ]
        }
      ]
    }
  ]
}