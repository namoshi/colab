{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnenBIxZwQ5hmdOWygVsdA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namoshi/colab/blob/master/optuna_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh9YlgrWJmdu",
        "outputId": "6e69810e-45ba-4fa0-8803-35630ba2c090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Optuna example that optimizes multi-layer perceptrons using PyTorch.\n",
        "\n",
        "In this example, we optimize the validation accuracy of fashion product recognition using\n",
        "PyTorch and FashionMNIST. We optimize the neural network architecture as well as the optimizer\n",
        "configuration. As it is too time consuming to use the whole FashionMNIST dataset,\n",
        "we here use a small subset of it.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "DIR = os.getcwd()\n",
        "EPOCHS = 20\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 10\n"
      ],
      "metadata": {
        "id": "d1JVQZoDKNhj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    layers = []\n",
        "\n",
        "    in_features = 28 * 28\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
        "        layers.append(nn.Dropout(p))\n",
        "\n",
        "        in_features = out_features\n",
        "    layers.append(nn.Linear(in_features, CLASSES))\n",
        "    layers.append(nn.LogSoftmax(dim=1))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def get_mnist():\n",
        "    # Load FashionMNIST dataset.\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=BATCHSIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Generate the model.\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "\n",
        "    # Generate the optimizers.\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [ \"AdamW\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    wd = trial.suggest_float(\"wd\", 1e-5, 1e-1)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "    # Get the FashionMNIST dataset.\n",
        "    train_loader, valid_loader = get_mnist()\n",
        "\n",
        "    # Training of the model.\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # Limiting training data for faster epochs.\n",
        "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "                break\n",
        "\n",
        "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "                # Limiting validation data.\n",
        "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                    break\n",
        "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "lKyH48QpKen-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=200, timeout=600)\n",
        "\n",
        "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: \", trial.value)\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpXJtp6KJzyz",
        "outputId": "508a5c48-1f0d-46c2-927a-4456a70aaae9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-09 05:07:55,457] A new study created in memory with name: no-name-e34905cc-30de-4f63-8109-082acccf1d15\n",
            "[I 2024-04-09 05:08:11,607] Trial 0 finished with value: 0.35078125 and parameters: {'n_layers': 1, 'n_units_l0': 124, 'dropout_l0': 0.3886136781164421, 'optimizer': 'SGD', 'lr': 0.0005082113876315916, 'wd': 0.04495805440188132}. Best is trial 0 with value: 0.35078125.\n",
            "[I 2024-04-09 05:08:23,623] Trial 1 finished with value: 0.83203125 and parameters: {'n_layers': 1, 'n_units_l0': 30, 'dropout_l0': 0.23505260616531085, 'optimizer': 'AdamW', 'lr': 0.003114869520637199, 'wd': 0.09817455957734346}. Best is trial 1 with value: 0.83203125.\n",
            "[I 2024-04-09 05:08:35,478] Trial 2 finished with value: 0.128125 and parameters: {'n_layers': 1, 'n_units_l0': 67, 'dropout_l0': 0.47723846922478047, 'optimizer': 'SGD', 'lr': 0.00011356020971542431, 'wd': 0.07591685155630945}. Best is trial 1 with value: 0.83203125.\n",
            "[I 2024-04-09 05:08:47,660] Trial 3 finished with value: 0.2140625 and parameters: {'n_layers': 3, 'n_units_l0': 64, 'dropout_l0': 0.41313769274688983, 'n_units_l1': 49, 'dropout_l1': 0.48560406842028037, 'n_units_l2': 128, 'dropout_l2': 0.4075049134089517, 'optimizer': 'SGD', 'lr': 0.003700173068508955, 'wd': 0.033365505916545614}. Best is trial 1 with value: 0.83203125.\n",
            "[I 2024-04-09 05:08:59,746] Trial 4 finished with value: 0.16953125 and parameters: {'n_layers': 3, 'n_units_l0': 40, 'dropout_l0': 0.2379555433489114, 'n_units_l1': 58, 'dropout_l1': 0.26231958190028615, 'n_units_l2': 62, 'dropout_l2': 0.31642974325934625, 'optimizer': 'SGD', 'lr': 0.011605052926951919, 'wd': 0.06429962591280702}. Best is trial 1 with value: 0.83203125.\n",
            "[I 2024-04-09 05:09:12,311] Trial 5 finished with value: 0.6296875 and parameters: {'n_layers': 2, 'n_units_l0': 62, 'dropout_l0': 0.34422601028585964, 'n_units_l1': 16, 'dropout_l1': 0.37641963276575524, 'optimizer': 'AdamW', 'lr': 7.858559971406089e-05, 'wd': 0.02728023977954506}. Best is trial 1 with value: 0.83203125.\n",
            "[I 2024-04-09 05:09:12,979] Trial 6 pruned. \n",
            "[I 2024-04-09 05:09:24,970] Trial 7 finished with value: 0.82890625 and parameters: {'n_layers': 2, 'n_units_l0': 50, 'dropout_l0': 0.20043939320930532, 'n_units_l1': 34, 'dropout_l1': 0.24701625870632765, 'optimizer': 'AdamW', 'lr': 0.0009725242196546432, 'wd': 0.06751699839540709}. Best is trial 1 with value: 0.83203125.\n",
            "[I 2024-04-09 05:09:25,607] Trial 8 pruned. \n",
            "[I 2024-04-09 05:09:37,587] Trial 9 finished with value: 0.76484375 and parameters: {'n_layers': 1, 'n_units_l0': 127, 'dropout_l0': 0.44233468694546163, 'optimizer': 'SGD', 'lr': 0.05733666583594441, 'wd': 0.0074899605861976784}. Best is trial 1 with value: 0.83203125.\n",
            "[I 2024-04-09 05:09:42,719] Trial 10 pruned. \n",
            "[I 2024-04-09 05:09:54,833] Trial 11 finished with value: 0.82265625 and parameters: {'n_layers': 2, 'n_units_l0': 17, 'dropout_l0': 0.20200511849909844, 'n_units_l1': 94, 'dropout_l1': 0.20684147736871256, 'optimizer': 'AdamW', 'lr': 0.002953555141537062, 'wd': 0.062652341283629}. Best is trial 1 with value: 0.83203125.\n",
            "[I 2024-04-09 05:09:55,638] Trial 12 pruned. \n",
            "[I 2024-04-09 05:10:07,637] Trial 13 finished with value: 0.83359375 and parameters: {'n_layers': 1, 'n_units_l0': 93, 'dropout_l0': 0.3072697356999039, 'optimizer': 'AdamW', 'lr': 0.0011939300725935561, 'wd': 0.0966258551591658}. Best is trial 13 with value: 0.83359375.\n",
            "[I 2024-04-09 05:10:19,622] Trial 14 finished with value: 0.77265625 and parameters: {'n_layers': 1, 'n_units_l0': 95, 'dropout_l0': 0.32133332305627405, 'optimizer': 'AdamW', 'lr': 0.00017323388617428387, 'wd': 0.099621760913434}. Best is trial 13 with value: 0.83359375.\n",
            "[I 2024-04-09 05:10:31,483] Trial 15 finished with value: 0.85 and parameters: {'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.26506284623612303, 'optimizer': 'AdamW', 'lr': 0.002429658890265685, 'wd': 0.0901718080197364}. Best is trial 15 with value: 0.85.\n",
            "[I 2024-04-09 05:10:43,386] Trial 16 finished with value: 0.79921875 and parameters: {'n_layers': 1, 'n_units_l0': 97, 'dropout_l0': 0.2857629855430263, 'optimizer': 'AdamW', 'lr': 0.017542480627754844, 'wd': 0.08514214988228536}. Best is trial 15 with value: 0.85.\n",
            "[I 2024-04-09 05:10:55,314] Trial 17 finished with value: 0.79609375 and parameters: {'n_layers': 1, 'n_units_l0': 97, 'dropout_l0': 0.36774664306399996, 'optimizer': 'AdamW', 'lr': 0.00032537134512194624, 'wd': 0.049640077841026205}. Best is trial 15 with value: 0.85.\n",
            "[I 2024-04-09 05:11:07,508] Trial 18 finished with value: 0.8515625 and parameters: {'n_layers': 1, 'n_units_l0': 110, 'dropout_l0': 0.32007422703407673, 'optimizer': 'AdamW', 'lr': 0.0016655396899085254, 'wd': 0.08792112881537055}. Best is trial 18 with value: 0.8515625.\n",
            "[I 2024-04-09 05:11:08,607] Trial 19 pruned. \n",
            "[I 2024-04-09 05:11:20,824] Trial 20 finished with value: 0.82578125 and parameters: {'n_layers': 2, 'n_units_l0': 82, 'dropout_l0': 0.3449370401678346, 'n_units_l1': 124, 'dropout_l1': 0.29894743782007777, 'optimizer': 'AdamW', 'lr': 0.0018222212272141964, 'wd': 0.05843623462489152}. Best is trial 18 with value: 0.8515625.\n",
            "[I 2024-04-09 05:11:32,759] Trial 21 finished with value: 0.86171875 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.3118725646388841, 'optimizer': 'AdamW', 'lr': 0.001308397098670084, 'wd': 0.08709522641017675}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:11:44,833] Trial 22 finished with value: 0.83828125 and parameters: {'n_layers': 1, 'n_units_l0': 111, 'dropout_l0': 0.3182027783613826, 'optimizer': 'AdamW', 'lr': 0.007882993105670946, 'wd': 0.08892079428570582}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:11:55,114] Trial 23 pruned. \n",
            "[I 2024-04-09 05:12:07,054] Trial 24 finished with value: 0.8390625 and parameters: {'n_layers': 1, 'n_units_l0': 84, 'dropout_l0': 0.32763083855918124, 'optimizer': 'AdamW', 'lr': 0.005741675276084924, 'wd': 0.08915355861859661}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:12:19,159] Trial 25 finished with value: 0.8359375 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.36285082427096677, 'optimizer': 'AdamW', 'lr': 0.0011677471534823711, 'wd': 0.07380290305376848}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:12:19,833] Trial 26 pruned. \n",
            "[I 2024-04-09 05:12:20,512] Trial 27 pruned. \n",
            "[I 2024-04-09 05:12:21,188] Trial 28 pruned. \n",
            "[I 2024-04-09 05:12:21,863] Trial 29 pruned. \n",
            "[I 2024-04-09 05:12:33,789] Trial 30 finished with value: 0.8203125 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.2362015739458063, 'optimizer': 'AdamW', 'lr': 0.019807071318738982, 'wd': 0.0401889937694402}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:12:45,848] Trial 31 finished with value: 0.8359375 and parameters: {'n_layers': 1, 'n_units_l0': 83, 'dropout_l0': 0.3306902512142375, 'optimizer': 'AdamW', 'lr': 0.004982382643777701, 'wd': 0.09156145446753104}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:12:57,920] Trial 32 finished with value: 0.83984375 and parameters: {'n_layers': 1, 'n_units_l0': 90, 'dropout_l0': 0.3064485258211847, 'optimizer': 'AdamW', 'lr': 0.005297370040837141, 'wd': 0.08161467111064354}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:13:09,960] Trial 33 finished with value: 0.82734375 and parameters: {'n_layers': 1, 'n_units_l0': 90, 'dropout_l0': 0.30502424821536805, 'optimizer': 'AdamW', 'lr': 0.00208100810630993, 'wd': 0.07308548206444296}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:13:22,060] Trial 34 finished with value: 0.83046875 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.24924326061640445, 'optimizer': 'AdamW', 'lr': 0.003584127078849198, 'wd': 0.08178506573771914}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:13:22,711] Trial 35 pruned. \n",
            "[I 2024-04-09 05:13:34,931] Trial 36 finished with value: 0.846875 and parameters: {'n_layers': 1, 'n_units_l0': 120, 'dropout_l0': 0.28150896727521024, 'optimizer': 'AdamW', 'lr': 0.002578021541458267, 'wd': 0.0848640787076161}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:13:35,615] Trial 37 pruned. \n",
            "[I 2024-04-09 05:13:36,295] Trial 38 pruned. \n",
            "[I 2024-04-09 05:13:36,975] Trial 39 pruned. \n",
            "[I 2024-04-09 05:13:38,227] Trial 40 pruned. \n",
            "[I 2024-04-09 05:13:50,201] Trial 41 finished with value: 0.82421875 and parameters: {'n_layers': 1, 'n_units_l0': 89, 'dropout_l0': 0.30503959331867797, 'optimizer': 'AdamW', 'lr': 0.004828889992368752, 'wd': 0.08215970614086045}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:14:02,232] Trial 42 finished with value: 0.828125 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.31297031664292424, 'optimizer': 'AdamW', 'lr': 0.012561689199728254, 'wd': 0.07835017157354712}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:14:14,204] Trial 43 finished with value: 0.828125 and parameters: {'n_layers': 1, 'n_units_l0': 53, 'dropout_l0': 0.294039076618004, 'optimizer': 'AdamW', 'lr': 0.0025123501060615523, 'wd': 0.08520001840129823}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:14:15,112] Trial 44 pruned. \n",
            "[I 2024-04-09 05:14:16,787] Trial 45 pruned. \n",
            "[I 2024-04-09 05:14:17,445] Trial 46 pruned. \n",
            "[I 2024-04-09 05:14:29,446] Trial 47 finished with value: 0.8125 and parameters: {'n_layers': 1, 'n_units_l0': 99, 'dropout_l0': 0.3523926048656587, 'optimizer': 'AdamW', 'lr': 0.010546029199134542, 'wd': 0.09607523654427141}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:14:30,129] Trial 48 pruned. \n",
            "[I 2024-04-09 05:14:30,827] Trial 49 pruned. \n",
            "[I 2024-04-09 05:14:31,503] Trial 50 pruned. \n",
            "[I 2024-04-09 05:14:43,484] Trial 51 finished with value: 0.83203125 and parameters: {'n_layers': 1, 'n_units_l0': 86, 'dropout_l0': 0.32653193111620327, 'optimizer': 'AdamW', 'lr': 0.006166554551082929, 'wd': 0.09044230607112297}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:14:44,160] Trial 52 pruned. \n",
            "[I 2024-04-09 05:14:44,874] Trial 53 pruned. \n",
            "[I 2024-04-09 05:14:56,841] Trial 54 finished with value: 0.8234375 and parameters: {'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.35032646854360794, 'optimizer': 'AdamW', 'lr': 0.015951020536856878, 'wd': 0.08039545565084244}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:15:08,902] Trial 55 finished with value: 0.80703125 and parameters: {'n_layers': 1, 'n_units_l0': 109, 'dropout_l0': 0.2672084253827039, 'optimizer': 'AdamW', 'lr': 0.008244958223670766, 'wd': 0.06816820807447213}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:15:09,575] Trial 56 pruned. \n",
            "[I 2024-04-09 05:15:10,273] Trial 57 pruned. \n",
            "[I 2024-04-09 05:15:23,043] Trial 58 finished with value: 0.8265625 and parameters: {'n_layers': 1, 'n_units_l0': 99, 'dropout_l0': 0.25645012379466287, 'optimizer': 'AdamW', 'lr': 0.0062409599043335776, 'wd': 0.056923024281833295}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:15:23,717] Trial 59 pruned. \n",
            "[I 2024-04-09 05:15:24,395] Trial 60 pruned. \n",
            "[I 2024-04-09 05:15:36,297] Trial 61 finished with value: 0.815625 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.3158651960022826, 'optimizer': 'AdamW', 'lr': 0.0073255940770453245, 'wd': 0.08826902422800963}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:15:38,309] Trial 62 pruned. \n",
            "[I 2024-04-09 05:15:50,418] Trial 63 finished with value: 0.821875 and parameters: {'n_layers': 1, 'n_units_l0': 123, 'dropout_l0': 0.2837146932745377, 'optimizer': 'AdamW', 'lr': 0.012405568455212882, 'wd': 0.08771637996975197}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:15:51,991] Trial 64 pruned. \n",
            "[I 2024-04-09 05:15:52,662] Trial 65 pruned. \n",
            "[I 2024-04-09 05:16:04,653] Trial 66 finished with value: 0.8359375 and parameters: {'n_layers': 1, 'n_units_l0': 68, 'dropout_l0': 0.37229492951872967, 'optimizer': 'AdamW', 'lr': 0.004870971659318501, 'wd': 0.04092333238881495}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:16:05,316] Trial 67 pruned. \n",
            "[I 2024-04-09 05:16:05,984] Trial 68 pruned. \n",
            "[I 2024-04-09 05:16:06,656] Trial 69 pruned. \n",
            "[I 2024-04-09 05:16:07,891] Trial 70 pruned. \n",
            "[I 2024-04-09 05:16:08,566] Trial 71 pruned. \n",
            "[I 2024-04-09 05:16:09,232] Trial 72 pruned. \n",
            "[I 2024-04-09 05:16:09,924] Trial 73 pruned. \n",
            "[I 2024-04-09 05:16:12,261] Trial 74 pruned. \n",
            "[I 2024-04-09 05:16:14,454] Trial 75 pruned. \n",
            "[I 2024-04-09 05:16:15,376] Trial 76 pruned. \n",
            "[I 2024-04-09 05:16:16,042] Trial 77 pruned. \n",
            "[I 2024-04-09 05:16:16,742] Trial 78 pruned. \n",
            "[I 2024-04-09 05:16:17,402] Trial 79 pruned. \n",
            "[I 2024-04-09 05:16:18,073] Trial 80 pruned. \n",
            "[I 2024-04-09 05:16:30,063] Trial 81 finished with value: 0.8421875 and parameters: {'n_layers': 1, 'n_units_l0': 89, 'dropout_l0': 0.3303175610226432, 'optimizer': 'AdamW', 'lr': 0.0052592404965400375, 'wd': 0.09589398279037248}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:16:42,073] Trial 82 finished with value: 0.8265625 and parameters: {'n_layers': 1, 'n_units_l0': 98, 'dropout_l0': 0.3085981114519987, 'optimizer': 'AdamW', 'lr': 0.0051975049374550115, 'wd': 0.09714313291887833}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:16:54,090] Trial 83 finished with value: 0.84765625 and parameters: {'n_layers': 1, 'n_units_l0': 80, 'dropout_l0': 0.348161093258221, 'optimizer': 'AdamW', 'lr': 0.007493434712714846, 'wd': 0.09143126426957228}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:16:56,428] Trial 84 pruned. \n",
            "[I 2024-04-09 05:16:58,225] Trial 85 pruned. \n",
            "[I 2024-04-09 05:17:02,168] Trial 86 pruned. \n",
            "[I 2024-04-09 05:17:14,373] Trial 87 finished with value: 0.83671875 and parameters: {'n_layers': 1, 'n_units_l0': 91, 'dropout_l0': 0.257522481430479, 'optimizer': 'AdamW', 'lr': 0.003055022934479182, 'wd': 0.09654339410974141}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:17:15,677] Trial 88 pruned. \n",
            "[I 2024-04-09 05:17:18,038] Trial 89 pruned. \n",
            "[I 2024-04-09 05:17:19,822] Trial 90 pruned. \n",
            "[I 2024-04-09 05:17:22,160] Trial 91 pruned. \n",
            "[I 2024-04-09 05:17:23,374] Trial 92 pruned. \n",
            "[I 2024-04-09 05:17:26,342] Trial 93 pruned. \n",
            "[I 2024-04-09 05:17:27,037] Trial 94 pruned. \n",
            "[I 2024-04-09 05:17:29,384] Trial 95 pruned. \n",
            "[I 2024-04-09 05:17:30,056] Trial 96 pruned. \n",
            "[I 2024-04-09 05:17:30,743] Trial 97 pruned. \n",
            "[I 2024-04-09 05:17:42,866] Trial 98 finished with value: 0.86171875 and parameters: {'n_layers': 1, 'n_units_l0': 75, 'dropout_l0': 0.33790315293336337, 'optimizer': 'AdamW', 'lr': 0.005713479995286435, 'wd': 0.09232030470874672}. Best is trial 21 with value: 0.86171875.\n",
            "[I 2024-04-09 05:17:45,252] Trial 99 pruned. \n",
            "[I 2024-04-09 05:17:46,565] Trial 100 pruned. \n",
            "[I 2024-04-09 05:17:58,657] Trial 101 finished with value: 0.83046875 and parameters: {'n_layers': 1, 'n_units_l0': 76, 'dropout_l0': 0.2701716179390383, 'optimizer': 'AdamW', 'lr': 0.0029629594280961044, 'wd': 0.09109921011777287}. Best is trial 21 with value: 0.86171875.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  102\n",
            "  Number of pruned trials:  59\n",
            "  Number of complete trials:  43\n",
            "Best trial:\n",
            "  Value:  0.86171875\n",
            "  Params: \n",
            "    n_layers: 1\n",
            "    n_units_l0: 112\n",
            "    dropout_l0: 0.3118725646388841\n",
            "    optimizer: AdamW\n",
            "    lr: 0.001308397098670084\n",
            "    wd: 0.08709522641017675\n"
          ]
        }
      ]
    }
  ]
}