{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[published] CelebA vanilla GAN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namoshi/colab/blob/master/%5Bpublished%5D_CelebA_vanilla_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D02QjJElmA_i"
      },
      "source": [
        "# Simple DCGAN implementation in Keras trained on 64x64 CelebA images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBnnFvK9mA_o"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LE57yr-mA_o"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u367rsRdRlR"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKnKW2OIlTzf",
        "outputId": "76ad27fe-8ce2-46cc-ba9c-23dd33c3dc42"
      },
      "source": [
        "!mkdir celeba_gan\n",
        "!gdown --id 1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684 -O celeba_gan/data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\n",
            "To: /content/celeba_gan/data.zip\n",
            "1.44GB [00:24, 58.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilay6yKNg0pv"
      },
      "source": [
        "!unzip -qq celeba_gan/data.zip -d celeba_gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhJsYkL_dTkE"
      },
      "source": [
        "## Create a `Dataset`\n",
        "\n",
        "We will work with 64x64 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3HZLjcPmUEK",
        "outputId": "6ce0e867-52a6-45d4-b349-542fc32f155a"
      },
      "source": [
        "from tensorflow import keras\n",
        "dataset = keras.preprocessing.image_dataset_from_directory('celeba_gan', label_mode=None, image_size=(64, 64), batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 202599 files belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7GrSQ74qMSv"
      },
      "source": [
        "dataset = dataset.map(lambda x: x / 255.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkj7ajZwdWij"
      },
      "source": [
        "## Display a sample image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "7fGS0fp_qLYk",
        "outputId": "339fdc19-4b7a-458c-fa02-ca90308c28c0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for x in dataset:\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow((x.numpy() * 255).astype('int32')[0])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-uN83VLmA_p"
      },
      "source": [
        "## Create the discriminator\n",
        "\n",
        "It maps a 64x64 image to a binary classification score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXYpRiV5mA_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d30d85-49a8-4391-ef8e-31519f95b532"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(64, 64, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 64)        3136      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 128)       131200    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 8193      \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy4TULqvmA_q"
      },
      "source": [
        "## Create the generator\n",
        "\n",
        "It mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap4CpcF9mA_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f39aaf6-e6a0-45a7-c5a0-69ac16fecd7f"
      },
      "source": [
        "latent_dim = 128\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 8192)              1056768   \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTr (None, 16, 16, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DT (None, 32, 32, 256)       524544    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DT (None, 64, 64, 512)       2097664   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 64, 64, 3)         38403     \n",
            "=================================================================\n",
            "Total params: 3,979,651\n",
            "Trainable params: 3,979,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aXJvWUkmA_q"
      },
      "source": [
        "## Create a GAN model that overrides `train_step`\n",
        "\n",
        "- We need 2 optimizers, so we also override `compile` to allow that.\n",
        "- We track our 2 losses with `Mean` metrics. We list them in the `metrics` property so that `fit` will reset the trackers at the start of each epoch.\n",
        "- The training logic is in `train_step`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-QtSLYbmA_r"
      },
      "source": [
        "\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
        "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "      return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flKPXazumA_r"
      },
      "source": [
        "## Create a callback that periodically saves generated images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKBfndPVmA_r"
      },
      "source": [
        "\n",
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yyeAipkmA_s"
      },
      "source": [
        "## Train the end-to-end model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqIA2mLsmA_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c7dd85-0c4e-4b60-be91-2dfdfb2ad24f"
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "6332/6332 [==============================] - 611s 96ms/step - d_loss: 0.5655 - g_loss: 1.7346\n",
            "Epoch 2/300\n",
            "6332/6332 [==============================] - 612s 97ms/step - d_loss: 0.6451 - g_loss: 1.1412\n",
            "Epoch 3/300\n",
            "6332/6332 [==============================] - 608s 96ms/step - d_loss: 0.6507 - g_loss: 1.0504\n",
            "Epoch 4/300\n",
            "6332/6332 [==============================] - 608s 96ms/step - d_loss: 0.6207 - g_loss: 1.1331\n",
            "Epoch 5/300\n",
            "6332/6332 [==============================] - 608s 96ms/step - d_loss: 0.6345 - g_loss: 1.0580\n",
            "Epoch 6/300\n",
            "6332/6332 [==============================] - 610s 96ms/step - d_loss: 0.6554 - g_loss: 1.0098\n",
            "Epoch 7/300\n",
            "6332/6332 [==============================] - 610s 96ms/step - d_loss: 0.6618 - g_loss: 0.9642\n",
            "Epoch 8/300\n",
            "6332/6332 [==============================] - 608s 96ms/step - d_loss: 0.6689 - g_loss: 0.9444\n",
            "Epoch 9/300\n",
            "6332/6332 [==============================] - 610s 96ms/step - d_loss: 0.6703 - g_loss: 0.9316\n",
            "Epoch 10/300\n",
            "6332/6332 [==============================] - 611s 96ms/step - d_loss: 0.6696 - g_loss: 0.9290\n",
            "Epoch 11/300\n",
            "6332/6332 [==============================] - 608s 96ms/step - d_loss: 0.6670 - g_loss: 0.9353\n",
            "Epoch 12/300\n",
            "6332/6332 [==============================] - 610s 96ms/step - d_loss: 0.6686 - g_loss: 0.9272\n",
            "Epoch 13/300\n",
            "6332/6332 [==============================] - 610s 96ms/step - d_loss: 0.6614 - g_loss: 0.9352\n",
            "Epoch 14/300\n",
            "6332/6332 [==============================] - 610s 96ms/step - d_loss: 0.6551 - g_loss: 0.9392\n",
            "Epoch 15/300\n",
            "6332/6332 [==============================] - 610s 96ms/step - d_loss: 0.6500 - g_loss: 0.9531\n",
            "Epoch 16/300\n",
            "6332/6332 [==============================] - 610s 96ms/step - d_loss: 0.6495 - g_loss: 0.9482\n",
            "Epoch 17/300\n",
            "6332/6332 [==============================] - 613s 97ms/step - d_loss: 0.6525 - g_loss: 0.9402\n",
            "Epoch 18/300\n",
            "6332/6332 [==============================] - 613s 97ms/step - d_loss: 0.6556 - g_loss: 0.9366\n",
            "Epoch 19/300\n",
            "6332/6332 [==============================] - 611s 96ms/step - d_loss: 0.6545 - g_loss: 0.9336\n",
            "Epoch 20/300\n",
            "6332/6332 [==============================] - 611s 96ms/step - d_loss: 0.6568 - g_loss: 0.9272\n",
            "Epoch 21/300\n",
            "6332/6332 [==============================] - 613s 97ms/step - d_loss: 0.6621 - g_loss: 0.9282\n",
            "Epoch 22/300\n",
            "6332/6332 [==============================] - 613s 97ms/step - d_loss: 0.6587 - g_loss: 0.9234\n",
            "Epoch 23/300\n",
            "6332/6332 [==============================] - 605s 95ms/step - d_loss: 0.6607 - g_loss: 0.9156\n",
            "Epoch 24/300\n",
            "6332/6332 [==============================] - 605s 96ms/step - d_loss: 0.6618 - g_loss: 0.9085\n",
            "Epoch 25/300\n",
            "6332/6332 [==============================] - 605s 96ms/step - d_loss: 0.6608 - g_loss: 0.9132\n",
            "Epoch 26/300\n",
            "6332/6332 [==============================] - 607s 96ms/step - d_loss: 0.6615 - g_loss: 0.9097\n",
            "Epoch 27/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6587 - g_loss: 0.9146\n",
            "Epoch 28/300\n",
            "6332/6332 [==============================] - 602s 95ms/step - d_loss: 0.6551 - g_loss: 0.9166\n",
            "Epoch 29/300\n",
            "6332/6332 [==============================] - 602s 95ms/step - d_loss: 0.6492 - g_loss: 0.9256\n",
            "Epoch 30/300\n",
            "6332/6332 [==============================] - 606s 96ms/step - d_loss: 0.6492 - g_loss: 0.9265\n",
            "Epoch 31/300\n",
            "6332/6332 [==============================] - 606s 96ms/step - d_loss: 0.6441 - g_loss: 0.9360\n",
            "Epoch 32/300\n",
            "6332/6332 [==============================] - 605s 96ms/step - d_loss: 0.6431 - g_loss: 0.9484\n",
            "Epoch 33/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6391 - g_loss: 0.9488\n",
            "Epoch 34/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6357 - g_loss: 0.9519\n",
            "Epoch 35/300\n",
            "6332/6332 [==============================] - 605s 96ms/step - d_loss: 0.6344 - g_loss: 0.9577\n",
            "Epoch 36/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6355 - g_loss: 0.9703\n",
            "Epoch 37/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6314 - g_loss: 0.9686\n",
            "Epoch 38/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6288 - g_loss: 0.9709\n",
            "Epoch 39/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6274 - g_loss: 0.9846\n",
            "Epoch 40/300\n",
            "6332/6332 [==============================] - 602s 95ms/step - d_loss: 0.6228 - g_loss: 0.9904\n",
            "Epoch 41/300\n",
            "6332/6332 [==============================] - 602s 95ms/step - d_loss: 0.6231 - g_loss: 0.9931\n",
            "Epoch 42/300\n",
            "6332/6332 [==============================] - 603s 95ms/step - d_loss: 0.6180 - g_loss: 1.0028\n",
            "Epoch 43/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6187 - g_loss: 1.0125\n",
            "Epoch 44/300\n",
            "6332/6332 [==============================] - 605s 95ms/step - d_loss: 0.6127 - g_loss: 1.0142\n",
            "Epoch 45/300\n",
            "6332/6332 [==============================] - 605s 96ms/step - d_loss: 0.6096 - g_loss: 1.0282\n",
            "Epoch 46/300\n",
            "6332/6332 [==============================] - 603s 95ms/step - d_loss: 0.6092 - g_loss: 1.0338\n",
            "Epoch 47/300\n",
            "6332/6332 [==============================] - 603s 95ms/step - d_loss: 0.6065 - g_loss: 1.0414\n",
            "Epoch 48/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6033 - g_loss: 1.0476\n",
            "Epoch 49/300\n",
            "6332/6332 [==============================] - 603s 95ms/step - d_loss: 0.6045 - g_loss: 1.0535\n",
            "Epoch 50/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6026 - g_loss: 1.0566\n",
            "Epoch 51/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.6007 - g_loss: 1.0693\n",
            "Epoch 52/300\n",
            "6332/6332 [==============================] - 604s 95ms/step - d_loss: 0.5994 - g_loss: 1.0728\n",
            "Epoch 53/300\n",
            "6332/6332 [==============================] - 606s 96ms/step - d_loss: 0.5978 - g_loss: 1.0664\n",
            "Epoch 54/300\n",
            "6332/6332 [==============================] - 613s 97ms/step - d_loss: 0.5962 - g_loss: 1.0759\n",
            "Epoch 55/300\n",
            "6332/6332 [==============================] - 618s 98ms/step - d_loss: 0.5959 - g_loss: 1.0798\n",
            "Epoch 56/300\n",
            "6332/6332 [==============================] - 617s 97ms/step - d_loss: 0.5944 - g_loss: 1.0856\n",
            "Epoch 57/300\n",
            "6332/6332 [==============================] - 616s 97ms/step - d_loss: 0.5929 - g_loss: 1.0830\n",
            "Epoch 58/300\n",
            "6332/6332 [==============================] - 607s 96ms/step - d_loss: 0.5928 - g_loss: 1.0965\n",
            "Epoch 59/300\n",
            "6332/6332 [==============================] - 602s 95ms/step - d_loss: 0.5918 - g_loss: 1.0863\n",
            "Epoch 60/300\n",
            "6332/6332 [==============================] - 602s 95ms/step - d_loss: 0.5916 - g_loss: 1.0855\n",
            "Epoch 61/300\n",
            "6332/6332 [==============================] - 601s 95ms/step - d_loss: 0.5899 - g_loss: 1.0885\n",
            "Epoch 62/300\n",
            "6332/6332 [==============================] - 600s 95ms/step - d_loss: 0.5900 - g_loss: 1.0938\n",
            "Epoch 63/300\n",
            "6332/6332 [==============================] - 600s 95ms/step - d_loss: 0.5874 - g_loss: 1.0988\n",
            "Epoch 64/300\n",
            "6332/6332 [==============================] - 600s 95ms/step - d_loss: 0.5881 - g_loss: 1.0982\n",
            "Epoch 65/300\n",
            "6332/6332 [==============================] - 599s 95ms/step - d_loss: 0.5871 - g_loss: 1.0998\n",
            "Epoch 66/300\n",
            "6332/6332 [==============================] - 599s 95ms/step - d_loss: 0.5856 - g_loss: 1.1079\n",
            "Epoch 67/300\n",
            "6332/6332 [==============================] - 599s 95ms/step - d_loss: 0.5849 - g_loss: 1.1081\n",
            "Epoch 68/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5844 - g_loss: 1.1011\n",
            "Epoch 69/300\n",
            "6332/6332 [==============================] - 600s 95ms/step - d_loss: 0.5829 - g_loss: 1.1075\n",
            "Epoch 70/300\n",
            "6332/6332 [==============================] - 599s 95ms/step - d_loss: 0.5838 - g_loss: 1.1020\n",
            "Epoch 71/300\n",
            "6332/6332 [==============================] - 599s 95ms/step - d_loss: 0.5831 - g_loss: 1.1105\n",
            "Epoch 72/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5811 - g_loss: 1.1116\n",
            "Epoch 73/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5793 - g_loss: 1.1184\n",
            "Epoch 74/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5740 - g_loss: 1.1351\n",
            "Epoch 75/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5750 - g_loss: 1.1250\n",
            "Epoch 76/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5732 - g_loss: 1.1353\n",
            "Epoch 77/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5720 - g_loss: 1.1402\n",
            "Epoch 78/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5716 - g_loss: 1.1412\n",
            "Epoch 79/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5691 - g_loss: 1.1579\n",
            "Epoch 80/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5678 - g_loss: 1.1448\n",
            "Epoch 81/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5669 - g_loss: 1.1597\n",
            "Epoch 82/300\n",
            "6332/6332 [==============================] - 601s 95ms/step - d_loss: 0.5656 - g_loss: 1.1619\n",
            "Epoch 83/300\n",
            "6332/6332 [==============================] - 603s 95ms/step - d_loss: 0.5648 - g_loss: 1.1700\n",
            "Epoch 84/300\n",
            "6332/6332 [==============================] - 602s 95ms/step - d_loss: 0.5647 - g_loss: 1.1682\n",
            "Epoch 85/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5627 - g_loss: 1.1656\n",
            "Epoch 86/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5617 - g_loss: 1.1701\n",
            "Epoch 87/300\n",
            "6332/6332 [==============================] - 601s 95ms/step - d_loss: 0.5593 - g_loss: 1.1799\n",
            "Epoch 88/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5591 - g_loss: 1.1805\n",
            "Epoch 89/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5558 - g_loss: 1.1924\n",
            "Epoch 90/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5541 - g_loss: 1.1917\n",
            "Epoch 91/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5548 - g_loss: 1.2001\n",
            "Epoch 92/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5522 - g_loss: 1.1986\n",
            "Epoch 93/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5526 - g_loss: 1.2059\n",
            "Epoch 94/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5503 - g_loss: 1.2117\n",
            "Epoch 95/300\n",
            "6332/6332 [==============================] - 600s 95ms/step - d_loss: 0.5485 - g_loss: 1.2160\n",
            "Epoch 96/300\n",
            "6332/6332 [==============================] - 602s 95ms/step - d_loss: 0.5470 - g_loss: 1.2256\n",
            "Epoch 97/300\n",
            "6332/6332 [==============================] - 599s 95ms/step - d_loss: 0.5467 - g_loss: 1.2214\n",
            "Epoch 98/300\n",
            "6332/6332 [==============================] - 597s 94ms/step - d_loss: 0.5448 - g_loss: 1.2287\n",
            "Epoch 99/300\n",
            "6332/6332 [==============================] - 598s 94ms/step - d_loss: 0.5445 - g_loss: 1.2224\n",
            "Epoch 100/300\n",
            "6332/6332 [==============================] - 600s 95ms/step - d_loss: 0.5421 - g_loss: 1.2353\n",
            "Epoch 101/300\n",
            "6332/6332 [==============================] - 600s 95ms/step - d_loss: 0.5410 - g_loss: 1.2393\n",
            "Epoch 102/300\n",
            "1362/6332 [=====>........................] - ETA: 7:49 - d_loss: 0.5379 - g_loss: 1.2468"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc-5MMQBdkrl"
      },
      "source": [
        "## You end up with images like this after ~30 epochs\n",
        "\n",
        "![results](https://i.imgur.com/h5MtQZ7l.png)"
      ]
    }
  ]
}